{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NihalSumesh/NLP/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3BdAFLUkXK2",
        "colab_type": "text"
      },
      "source": [
        "# This program will help predict whether a document is positive or negative.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSFyRbESkPUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2nrz1yFZouB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading the dataset\n",
        "old = np.load\n",
        "np.load = lambda *a,**k: old(*a,**k,allow_pickle=True)\n",
        "top_words = 5000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = top_words)\n",
        "\n",
        "np.load = old\n",
        "del(old)\n",
        "\n",
        "#pad dataset to a maximum review length in words\n",
        "max_words = 500\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_words)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOxNpVVSbwJ7",
        "colab_type": "code",
        "outputId": "58a0c089-cfd4-46fe-ed03-2d5c9aa4a71c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 250)               2000250   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 2,163,605\n",
            "Trainable params: 2,163,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DJr6Fim1GLV",
        "colab_type": "code",
        "outputId": "9bbfaaa4-0f1e-4e46-c426-0e9ed094013e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=128, verbose=2)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            " - 2s - loss: 0.4793 - acc: 0.7382 - val_loss: 0.2817 - val_acc: 0.8834\n",
            "Epoch 2/5\n",
            " - 2s - loss: 0.2234 - acc: 0.9118 - val_loss: 0.2773 - val_acc: 0.8834\n",
            "Epoch 3/5\n",
            " - 2s - loss: 0.1748 - acc: 0.9338 - val_loss: 0.2945 - val_acc: 0.8804\n",
            "Epoch 4/5\n",
            " - 2s - loss: 0.1317 - acc: 0.9528 - val_loss: 0.3204 - val_acc: 0.8778\n",
            "Epoch 5/5\n",
            " - 2s - loss: 0.0879 - acc: 0.9728 - val_loss: 0.3735 - val_acc: 0.8742\n",
            "Accuracy: 87.42%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}